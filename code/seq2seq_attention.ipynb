{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XI6X1MvhhFwD"
   },
   "source": [
    "\n",
    "# **Financial Time Series prediction using LSTM and Multivariate Linear Regression**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "TN3xQ0d8ncyl",
    "outputId": "7011b461-9cce-4815-fc41-fa5d8d4382fb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-BsEp5_npmb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kO7UjVooB1H"
   },
   "source": [
    "##Intro - data exploration, visualization etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "L9Jfv7u1nqJs",
    "outputId": "a6f0d6c7-e39c-4116-c6d8-f58b69e14842"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>330.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>326.450012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321.910004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>315.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6750</th>\n",
       "      <td>2553.169922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>2557.639893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6752</th>\n",
       "      <td>2559.360107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6753</th>\n",
       "      <td>2561.260010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>2562.100098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6755 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Adj Close\n",
       "0      330.220001\n",
       "1      326.450012\n",
       "2      321.910004\n",
       "3      321.000000\n",
       "4      315.440002\n",
       "...           ...\n",
       "6750  2553.169922\n",
       "6751  2557.639893\n",
       "6752  2559.360107\n",
       "6753  2561.260010\n",
       "6754  2562.100098\n",
       "\n",
       "[6755 rows x 1 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sandp500/all_stocks_5yr.csv', index_col = \"Name\")\n",
    "# sp500 = pd.read_csv('ARIMA_Results.csv')\n",
    "# sp500 = sp500.loc[:,[\"residuals\"]][3000:]\n",
    "sp500 = pd.read_csv('SP500.csv')\n",
    "sp500 = sp500.loc[:,[\"Adj Close\"]]\n",
    "sp500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uftKnyRc78x"
   },
   "source": [
    "We'll need this dataset in the end of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "VHGtr9rUnqSC",
    "outputId": "3d5cafc7-65c4-4fb7-8148-b0abfae8fcb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 330.220001]\n",
      " [ 326.450012]\n",
      " [ 321.910004]\n",
      " ...\n",
      " [2559.360107]\n",
      " [2561.26001 ]\n",
      " [2562.100098]]\n"
     ]
    }
   ],
   "source": [
    "sp500_close_prices = sp500.values.astype(float)\n",
    "print(sp500_close_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSi5XHtdn_yk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0083],\n",
      "        [0.0066],\n",
      "        [0.0046],\n",
      "        [0.0042],\n",
      "        [0.0018],\n",
      "        [0.0015],\n",
      "        [0.0000],\n",
      "        [0.0014],\n",
      "        [0.0017],\n",
      "        [0.0004],\n",
      "        [0.0010],\n",
      "        [0.0021],\n",
      "        [0.0073],\n",
      "        [0.0092],\n",
      "        [0.0087],\n",
      "        [0.0075]]) tensor([0.0083])\n",
      "tensor([[0.0066],\n",
      "        [0.0046],\n",
      "        [0.0042],\n",
      "        [0.0018],\n",
      "        [0.0015],\n",
      "        [0.0000],\n",
      "        [0.0014],\n",
      "        [0.0017],\n",
      "        [0.0004],\n",
      "        [0.0010],\n",
      "        [0.0021],\n",
      "        [0.0073],\n",
      "        [0.0092],\n",
      "        [0.0087],\n",
      "        [0.0075],\n",
      "        [0.0083]]) tensor([0.0103])\n"
     ]
    }
   ],
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "#Market close data extraction\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "#Data normalization\n",
    "scaler = MinMaxScaler()\n",
    "training_data = scaler.fit_transform(sp500_close_prices)\n",
    "\n",
    "seq_length = 16\n",
    "x, y = create_sequences(training_data, seq_length)\n",
    "\n",
    "train_size = 5500\n",
    "validate_size = 500\n",
    "test_size = len(y) - train_size - validate_size\n",
    "batch_size_value = 64\n",
    "dataX = torch.Tensor(np.array(x))\n",
    "dataY = torch.Tensor(np.array(y))\n",
    "\n",
    "X_train = torch.Tensor(np.array(x[0:train_size]))\n",
    "Y_train = torch.Tensor(np.array(y[0:train_size]))\n",
    "\n",
    "training_dataset = TensorDataset(X_train,Y_train)\n",
    "train_loader = DataLoader(training_dataset, num_workers=1, shuffle=True,batch_size = batch_size_value,drop_last = True)\n",
    "\n",
    "X_validate = torch.Tensor(np.array(x[train_size:train_size+validate_size]))\n",
    "Y_validate = torch.Tensor(np.array(y[train_size:train_size+validate_size]))\n",
    "\n",
    "validate_dataset = TensorDataset(X_validate,Y_validate)\n",
    "validate_loader = DataLoader(validate_dataset, num_workers=1, shuffle=True,batch_size = batch_size_value,drop_last = True)\n",
    "\n",
    "X_test = torch.Tensor(np.array(x[train_size+validate_size:len(x)]))\n",
    "Y_test = torch.Tensor(np.array(y[train_size+validate_size:len(y)]))\n",
    "print(X_train[0],Y_train[0])\n",
    "print(X_train[1],Y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5RpIZWcVr0d0"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDqu336In_7U"
   },
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, code_hidden_size, hidden_size, time_step):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.code_hidden_size = code_hidden_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.T = time_step\n",
    "\n",
    "        self.W = nn.Linear(in_features=2 * hidden_size, out_features=code_hidden_size)\n",
    "        self.U = nn.Linear(in_features=code_hidden_size, out_features=code_hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.V = nn.Linear(in_features=code_hidden_size, out_features=1)\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=self.hidden_size)\n",
    "        self.tilde = nn.Linear(in_features=self.code_hidden_size + 1, out_features=1)\n",
    "        self.fc1 = nn.Linear(in_features=code_hidden_size + hidden_size, out_features=hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, encoder_output, y_seq, d , s):\n",
    "        y_seq = y_seq.transpose(0,1)  #   1*64*1 -->64*1*1\n",
    "        encoder_output = encoder_output.transpose(0,1)  # [8, 64, 16]->[64, 8, 16]\n",
    "\n",
    "        # (seq_len, batch,  hidden_size):    \n",
    "        batch_size = encoder_output.size(0)  \n",
    "#         d = self.init_variable(1, batch_size, self.hidden_size)#. [1, 64, 16]\n",
    "#         s = self.init_variable(1, batch_size, self.hidden_size)\n",
    "        \n",
    "        ct = self.init_variable(batch_size, self.hidden_size)    # [64, 16]\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            # batch_size * time_step * (encoder_hidden_size + decoder_hidden_size)\n",
    "            # [time_step, 64, 16] ->[64 , tstep, 16] \n",
    "          \n",
    "            h = encoder_output  # [64, 8, 16]\n",
    "            d_s = torch.cat((self.embedding_hidden(d), self.embedding_hidden(s)), 2)    # [64 , 1, 16*2]\n",
    "            z1 = self.W(d_s)  # [64 ,1, 16*2]-> [64 , 1, 16]\n",
    "            z2 = self.U(h)  # [64, 8, 16]->[64, 8, 16]\n",
    "            x = z1 + z2  # [64, 1, 16] + [64, 8, 16] = [64, 8, 16]\n",
    "            z3 = self.V(self.tanh(x))   #   [64, 8, 16]->[64, 8, 1]\n",
    "\n",
    "            beta_t = F.softmax(z3.view(batch_size, -1), dim=1)\n",
    "            # yc 64*1*1\n",
    "            # h [64, 8, 16]\n",
    "\n",
    "            # [64, 1, 8] * [64, 8, 16] = [64, 1, 16] -> [64, 16]   batch_size * encoder_hidden_size\n",
    "            ct = torch.bmm(beta_t.unsqueeze(1), h).squeeze(1)  # [64, 16]\n",
    "            \n",
    "            y_past = y_seq[:,t,:] # [64, 1]\n",
    "            yc = torch.cat((y_past, ct), dim=1)  \n",
    "            y_tilde = self.tilde(yc)\n",
    "            _, states = self.lstm(y_tilde.unsqueeze(0), (d, s))    # [1, 64, 1]  [1, 64, 16]\n",
    "            d = states[0]\n",
    "            \n",
    "        y_res = self.fc2(self.fc1(torch.cat((d.squeeze(0), ct), dim=1)))\n",
    "        return y_res\n",
    "\n",
    "    def init_variable(self, *args):\n",
    "        zero_tensor = torch.zeros(args)\n",
    "        if torch.cuda.is_available():\n",
    "            zero_tensor = zero_tensor.cuda()\n",
    "        return Variable(zero_tensor)\n",
    "\n",
    "    def embedding_hidden(self, x):\n",
    "        return x.repeat(self.T, 1, 1).permute(1, 0, 2)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size,num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,num_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "      \n",
    "        output, (hidden_out, cell_out) = self.lstm(x)\n",
    "        \n",
    "        return output, (hidden_out, cell_out)\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size,num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "  \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,num_layers)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,hidden,cell):\n",
    "        \n",
    "        \n",
    "     \n",
    "        output, (hidden_out, cell_out) = self.lstm(x, (hidden, cell))\n",
    "        \n",
    "        return output, (hidden_out, cell_out)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layers,out_dims,attention_flag = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(input_size,hidden_size,num_layers)\n",
    "        if attention_flag == True:\n",
    "            self.decoder = AttnDecoder(hidden_size, hidden_size, 1)\n",
    "        if attention_flag == False:\n",
    "            self.decoder = Decoder(input_size,hidden_size,num_layers)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, out_dims)\n",
    "        \n",
    "        \n",
    "    def forward(self, enc_input, dec_input):\n",
    "        \n",
    "        encoder_output,(h_out,c_out) = self.encoder(enc_input)  # torch.Size([64, 8, 1])\n",
    "\n",
    "        #dec_input [64, 1, 1]     \n",
    "        # h_out  [1, 64, 16]\n",
    "        \n",
    "        if attention_flag == True:\n",
    "            y_res = self.decoder(encoder_output, dec_input,h_out,c_out)\n",
    "        if attention_flag == False:\n",
    "            _, (decoder_h_out, _) = self.decoder(dec_input,h_out,c_out)\n",
    "            y_res = self.fc(decoder_h_out)\n",
    "\n",
    "       \n",
    "        return y_res\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9zKfHX-cr3H_"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (lstm): LSTM(1, 32)\n",
       "  )\n",
       "  (decoder): AttnDecoder(\n",
       "    (W): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (U): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (V): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (lstm): LSTM(1, 32)\n",
       "    (tilde): Linear(in_features=33, out_features=1, bias=True)\n",
       "    (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 0.005\n",
    "input_dim = 1\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "output_dim = 1\n",
    "output_length = 1\n",
    "attention_flag = True\n",
    "\n",
    "model = Seq2Seq(input_dim,hidden_size,num_layers,output_dim,attention_flag)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiazeyu/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 64, 1])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.00011,validate_loss: 0.00033\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-90701fdd6f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#decoder_input = X_train[:,-1,:].unsqueeze(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# obtain the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-fd692b3412ea>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc_input, dec_input)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# torch.Size([64, 8, 1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m#dec_input [64, 1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-fd692b3412ea>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# Propagate input through LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    526\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_get_flat_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_parameter_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_flat_weights_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_flat_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_flat_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_flat_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayerparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayerparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mall_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        X_train,Y_train = data\n",
    "        Y_train = Y_train.unsqueeze(0)\n",
    "        \n",
    "        model.train()\n",
    "        # decoder çš„è¾“å…¥\n",
    "        decoder_input = torch.zeros(output_length,batch_size_value,output_dim)  # 1,64,1\n",
    "\n",
    "        #decoder_input = X_train[:,-1,:].unsqueeze(1)\n",
    "        train_pred = model(X_train.transpose(0,1), decoder_input)\n",
    "        \n",
    "        # obtain the loss function\n",
    "        train_loss = criterion(train_pred, Y_train)\n",
    "        train_loss.backward(retain_graph=True) #backpropagation\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        for valdiate_data in validate_loader:\n",
    "            X_validate,Y_validate = valdiate_data\n",
    "            #decoder_input = X_validate[:,-1,:].unsqueeze(1)\n",
    "            validate_pred =  model(X_validate.transpose(0,1),decoder_input)\n",
    "            validate_loss = criterion(validate_pred,Y_validate)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(\"Epoch: %d, train_loss: %1.5f,validate_loss: %1.5f\" % (epoch, train_loss,validate_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MOOBXfWfr6lc"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "pRbyXUb0r8iF",
    "outputId": "44bf2456-0e3b-4fb4-9102-e831808f5a7c"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "train_predict = model(dataX.transpose(0,1),torch.zeros(1,dataX.size(0),1))\n",
    "#print(train_predict.size(),dataY.size())\n",
    "train_predict = train_predict.squeeze(0)\n",
    "data_predict = train_predict.data.numpy()\n",
    "\n",
    "dataY_plot = dataY.data.numpy()\n",
    "\n",
    "data_predict = scaler.inverse_transform(data_predict)\n",
    "dataY_plot = scaler.inverse_transform(dataY_plot)\n",
    "\n",
    "plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "plt.plot(dataY_plot, label = \"S&P actual value\")\n",
    "plt.plot(data_predict, label = \"S&P predicted value\")\n",
    "plt.suptitle('S&P500 Forecasting')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(dataY_plot[(train_size+validate_size):], data_predict[(train_size+validate_size):])   # 5500  \n",
    "mae = mean_absolute_error(dataY_plot[(train_size+validate_size):], data_predict[(train_size+validate_size):])\n",
    "\n",
    "print(f'X_test MSE: {mse}')\n",
    "print(f'X_test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataY_plot[(train_size+validate_size):], label = \"S&P actual value\")\n",
    "plt.plot(data_predict[(train_size+validate_size):], label = \"S&P predicted value\")\n",
    "plt.suptitle('S&P500 Forecasting')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ROBT407_FinalProject.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
